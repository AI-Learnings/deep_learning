{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training of NN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjUrMOvabOe2"
      },
      "source": [
        "# Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbI0W0pxbTKj"
      },
      "source": [
        "Lets suppose there is a 2d dataset, where y = 2x. And the deep learning algorithm has the task to take the known dataset and predict the relationship for unknown dataset. if f(x) = 2x. So the cost function is as given below:\r\n",
        "\r\n",
        "                J(w) = 1/2m [ sum (y - wx) ** 2]\r\n",
        "\r\n",
        " the work of the model is to find w. Plot by taking various values of j(w) with respect to various value of w, after that we can find out a value of w for which j(w) is smallest. Choose that value. In real world we have multiple values of w, means w is multi dimensional. So to find out best values of w, we use an optimization algorithm known as Gradient Descent. It's an iterative optimization algorithm to find minima of a function. To find minimum of a function by using gradient descent, one takes steps propertional to the negative of the gradient of the function at the current point. \r\n",
        "\r\n",
        "What does it mean? We start at a random initial value of w. The gradient is the slope of the cost function curve at the point where weights are initialized. It's helpful to find direction (whether positive or negative) and the magnitude of the step is controlled by a value called learning rate. The larger the value, the larger the steps and the smaller the value, the smaller the step. \r\n",
        "\r\n",
        "Then the weights are updated as \r\n",
        "\r\n",
        "W_new = W_old - n . dj/dw\r\n",
        "\r\n",
        "dj/dw = Gradient of cost function j.<br>\r\n",
        "n = learning rate.<br>\r\n",
        "\r\n",
        "The process is iterative untill we find j(w) is minimum or very close to minimum. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CvzALGKbTIg"
      },
      "source": [
        "# Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-tMeStmbS8g"
      },
      "source": [
        "In supervised learning, we know the value or the true label of the given features. But for the initialized weights, the prediction is not equals to the actual values. The backpropagation works as:<br>\r\n",
        "1. Calculate the error between actual value and predicted value. Lets the error is equal to the cost function J.<br>\r\n",
        "2. Propagate the error back into the network and update each weight and bias as per the above equation of gradient descent.\r\n",
        "3. The error is calculated as the sum of square of difference between actual and predicted values. \r\n",
        "4. Then the weights and biases are updated by propagting the error.\r\n",
        "5. The biases and weights are updated by subtracting gradient of error with respect to corresponding weight or bias multiplied by learning rate.\r\n",
        "\r\n",
        "          \r\n",
        "                        W1 = W1 - n. dj/dW1\r\n",
        "\r\n",
        "## Complete training Algorithm\r\n",
        "1. Initialize the weights and biases.\r\n",
        "2. Iteratively repeat from step 3 to step 6.\r\n",
        "3. Calculate network output using forward propagation.\r\n",
        "4. Calculate the error between the actual value and predicted value.\r\n",
        "5. Update weights and biases through backpropagation.\r\n",
        "6. Repeat the steps until number of epoches/iterations is reached or error between ground truth and predicted value is below the predefined threshold.\r\n",
        "\r\n",
        "## Vanishing Gradient\r\n",
        "This is a problem with sigmoid activation function that prevent neural network booming sooner. The gradient of error with respect to weights and biases are too small. Value of sigmoid function is between 0 to 1 and gradient of sigmoid function is from 0 to 0.25. So when we back propagate the errors, we keep multiplying factors less than 1. So the gradient gets smaller and smaller on moving backwards in the network. This means the neurons in earlier layers learn too slowly than the layers on later layer. The result is training gets too slower and takes longer time. Thats the cause why we don't use sigmoid function or similar activation function since they are prone to vanishing gradient problem. \r\n",
        "\r\n",
        "##Activation Functions\r\n",
        "There are 7 types of activation functions, we can use in a neural network. Those are \r\n",
        "1. Binary step function\r\n",
        "2. Linear function\r\n",
        "3. Sigmoid function\r\n",
        "4. Hyperbolic tangent function\r\n",
        "5. ReLU (rectified linear unit)\r\n",
        "6. Leaky relu\r\n",
        "7. Softmax\r\n",
        "\r\n",
        "The following points should be kept in your mind before applying and activation function. These are:\r\n",
        "- The sigmoid and hyperbolic tangent functions are avoided in many applications now a days due to vanishing gradient problem.\r\n",
        "- The Relu is a general activation function and is used in most of the usecases now a days.\r\n",
        "- Note that the relu is only used in hidden layers. \r\n",
        "- Generally, you can begin with using relu then switch to other activation function, if it doesn't yield good result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOzd4AK2Tbkm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4ufcaA4bKb9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}